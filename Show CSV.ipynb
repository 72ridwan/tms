{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the features that has and hasn't been done:\n",
    "\n",
    "- [X] Display points from all views simultaneously.\n",
    "- [X] Give color according to vehicle type\n",
    "- [ ] Display the CCTV views\n",
    "- [ ] Display the bounding boxes to CCTV views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cctv_folder_parent</th>\n",
       "      <th>map_image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SIMPANG 3 DPR</td>\n",
       "      <td>SIMPANG 3 DPR.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SIMPANG 4 CUNGKING</td>\n",
       "      <td>SIMPANG 4 CUNGKING.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SIMPANG 4 PATUNG KUDA</td>\n",
       "      <td>SIMPANG 4 PATUNG KUDA.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SIMPANG 5 PUSAT KOTA</td>\n",
       "      <td>SIMPANG 5 BANYUWANGI.jpeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cctv_folder_parent              map_image_name\n",
       "0          SIMPANG 3 DPR          SIMPANG 3 DPR.jpeg\n",
       "1     SIMPANG 4 CUNGKING     SIMPANG 4 CUNGKING.jpeg\n",
       "2  SIMPANG 4 PATUNG KUDA  SIMPANG 4 PATUNG KUDA.jpeg\n",
       "3   SIMPANG 5 PUSAT KOTA   SIMPANG 5 BANYUWANGI.jpeg"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "region_data = pd.read_csv('regions.csv')\n",
    "region_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_name</th>\n",
       "      <th>cctv_view_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SIMPANG 3 DPR</td>\n",
       "      <td>dpr selatan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SIMPANG 3 DPR</td>\n",
       "      <td>dpr timur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SIMPANG 3 DPR</td>\n",
       "      <td>dpr utara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SIMPANG 4 PATUNG KUDA</td>\n",
       "      <td>patungkuda barat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SIMPANG 4 PATUNG KUDA</td>\n",
       "      <td>patungkuda selatan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SIMPANG 4 PATUNG KUDA</td>\n",
       "      <td>patungkuda utara</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             region_name      cctv_view_name\n",
       "0          SIMPANG 3 DPR         dpr selatan\n",
       "1          SIMPANG 3 DPR           dpr timur\n",
       "2          SIMPANG 3 DPR           dpr utara\n",
       "3  SIMPANG 4 PATUNG KUDA    patungkuda barat\n",
       "4  SIMPANG 4 PATUNG KUDA  patungkuda selatan\n",
       "5  SIMPANG 4 PATUNG KUDA    patungkuda utara"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cctv_data = pd.read_csv('cctv_views.csv')\n",
    "cctv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCTV VIEWS : ['patungkuda barat', 'patungkuda selatan', 'patungkuda utara']\n",
      "MAP PATH   : map/SIMPANG 4 PATUNG KUDA.jpeg\n",
      "REGION COORDINATES:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>view</th>\n",
       "      <th>pt1a</th>\n",
       "      <th>pt1b</th>\n",
       "      <th>pt1c</th>\n",
       "      <th>pt1d</th>\n",
       "      <th>pt2a</th>\n",
       "      <th>pt2b</th>\n",
       "      <th>pt2c</th>\n",
       "      <th>pt2d</th>\n",
       "      <th>pt3a</th>\n",
       "      <th>pt3b</th>\n",
       "      <th>pt3c</th>\n",
       "      <th>pt3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patungkuda selatan</td>\n",
       "      <td>97 273</td>\n",
       "      <td>363 236</td>\n",
       "      <td>1074 476</td>\n",
       "      <td>187 770</td>\n",
       "      <td>0 0</td>\n",
       "      <td>1080 0</td>\n",
       "      <td>1080 720</td>\n",
       "      <td>0 720</td>\n",
       "      <td>400 717</td>\n",
       "      <td>295 644</td>\n",
       "      <td>392 513</td>\n",
       "      <td>492 587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patungkuda barat</td>\n",
       "      <td>132 283</td>\n",
       "      <td>396 262</td>\n",
       "      <td>1080 505</td>\n",
       "      <td>211 720</td>\n",
       "      <td>0 0</td>\n",
       "      <td>1080 0</td>\n",
       "      <td>1080 720</td>\n",
       "      <td>0 720</td>\n",
       "      <td>364 296</td>\n",
       "      <td>475 236</td>\n",
       "      <td>578 379</td>\n",
       "      <td>458 450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patungkuda utara</td>\n",
       "      <td>510 170</td>\n",
       "      <td>668 168</td>\n",
       "      <td>664 437</td>\n",
       "      <td>0 390</td>\n",
       "      <td>0 0</td>\n",
       "      <td>1080 0</td>\n",
       "      <td>1080 720</td>\n",
       "      <td>0 720</td>\n",
       "      <td>648 167</td>\n",
       "      <td>748 239</td>\n",
       "      <td>598 437</td>\n",
       "      <td>497 362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 view     pt1a      pt1b       pt1c      pt1d pt2a     pt2b  \\\n",
       "0  patungkuda selatan   97 273   363 236   1074 476   187 770  0 0   1080 0   \n",
       "1    patungkuda barat  132 283   396 262   1080 505   211 720  0 0   1080 0   \n",
       "2    patungkuda utara  510 170   668 168    664 437     0 390  0 0   1080 0   \n",
       "\n",
       "       pt2c   pt2d      pt3a      pt3b      pt3c      pt3d  \n",
       "0  1080 720  0 720   400 717   295 644   392 513   492 587  \n",
       "1  1080 720  0 720   364 296   475 236   578 379   458 450  \n",
       "2  1080 720  0 720   648 167   748 239   598 437   497 362  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a CCTV path of image whose region has been detected\n",
    "# Define the map path as well.\n",
    "\n",
    "# You can freely change this depending on the condition of your database.\n",
    "region_name = \"SIMPANG 4 PATUNG KUDA\"\n",
    "cctv_range = {'start':0, 'end': 324}\n",
    "cctv_time = '1200'\n",
    "\n",
    "region_cctv_views = cctv_data[cctv_data['region_name'] == region_name]['cctv_view_name'].values.tolist()\n",
    "\n",
    "region_map_path = region_data[region_data['cctv_folder_parent'] == region_name]\n",
    "region_map_path = 'map/' + region_map_path['map_image_name'].values.tolist()[0]\n",
    "\n",
    "region_coords = pd.read_csv('coords/cctv/{:}.csv'.format(region_name))\n",
    "\n",
    "print(\"CCTV VIEWS :\", region_cctv_views)\n",
    "print(\"MAP PATH   :\", region_map_path)\n",
    "print(\"REGION COORDINATES:\")\n",
    "region_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_image = cv2.imread(region_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points(pandas_frame, view_name):\n",
    "    polygons = {}\n",
    "    row = pandas_frame[pandas_frame['view'] == view_name]\n",
    "    point_id = ['a', 'b', 'c', 'd']\n",
    "    polygon_id = ['1', '2', '3']\n",
    "    for i in polygon_id:\n",
    "        polygon = []\n",
    "        for j in point_id:\n",
    "            point_name = 'pt'+ i + j\n",
    "            point_array = [int(p) for p in row[point_name].values.tolist()[0].split()]\n",
    "            polygon.append(point_array)\n",
    "        polygons[i] = np.float32(polygon)\n",
    "    return polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warpPerspectivePoints(pts, M):\n",
    "    n = pts.shape[0]\n",
    "    trans = np.hstack((pts, np.ones((n,1)))) # Add ones at the bottom of matrix\n",
    "    trans = np.matmul(M, np.transpose(trans))\n",
    "    return np.transpose(trans[0:2,:] / trans[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pseudocode:\n",
    "\n",
    "For every CCTV views:\n",
    "\n",
    "1. Eliminate non-vehicles point (can be obtained from the \"object\" header)\n",
    "   For example, vehicles: truck, car, motorbike\n",
    "1. For every bounding box vehicles:\n",
    "   1. Find the bounding box center point\n",
    "   1. Map the point according to transformation matrix M\n",
    "1. Now, for displaying purposes:\n",
    "   1. Draw the map and all the transformed points\n",
    "   1. In new window, draw the CCTV image with boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_vehicle_labels = ['bicycle', 'car', 'motorbike', 'bus', 'truck']\n",
    "\n",
    "def eliminate_non_vehicle(series):\n",
    "    detections = series['object_probs'].split(' ')\n",
    "    if detections[0] in coco_vehicle_labels:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def pause_and_is_finished():\n",
    "    # Pauses and quit button purposes\n",
    "    k = cv2.waitKey(25) & 0xFF\n",
    "    finished = k == ord_q\n",
    "    if k == ord_p:\n",
    "        while True:\n",
    "            k = cv2.waitKey(25) & 0xFF\n",
    "            finished = k == ord_q\n",
    "            if k == ord_p or k == ord_q:\n",
    "                break\n",
    "    return finished\n",
    "\n",
    "def generate_equal_rgb_color_distance(n):\n",
    "    colors = []\n",
    "    for i in range(n):\n",
    "        color = np.uint8(cv2.cvtColor(np.float32([[[i*360/n, 0.8, 0.9]]]), cv2.COLOR_HSV2RGB)[0, 0] * 255)\n",
    "        colors.append(color)\n",
    "    return colors\n",
    "\n",
    "coco_colors = generate_equal_rgb_color_distance(len(coco_vehicle_labels))\n",
    "coco_colors\n",
    "\n",
    "def get_color_from_class(row):\n",
    "    class_name = row.split()[0]\n",
    "    class_index = coco_vehicle_labels.index(class_name)\n",
    "    return coco_colors[class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a dictionary to store variables.\n",
    "# These variables include precomputed value as well, such as\n",
    "# the transformation matrix.\n",
    "\n",
    "objs = {}\n",
    "for i in range(len(region_cctv_views)):\n",
    "    obj_dict = {}\n",
    "    \n",
    "    rctv = region_cctv_views[i]\n",
    "    path_cctv_view = './frame/cctv_{:}_{:} {:}_x264.mp4/'.format(region_name, rctv, cctv_time)\n",
    "    \n",
    "    polygons = get_points(region_coords, rctv)\n",
    "\n",
    "    pts1 = polygons['1']\n",
    "    pts2 = polygons['3']\n",
    "\n",
    "    # Get transformation matrix\n",
    "    M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    pts_transform = np.int32(warpPerspectivePoints(pts1, M))    \n",
    "\n",
    "    # Get detections CSV file name length\n",
    "    # It is assumed that all files has the same name length.\n",
    "    file_ext_first_file = os.path.splitext(os.listdir(path_cctv_view)[0])\n",
    "    filename_length = len(file_ext_first_file[0])\n",
    "    \n",
    "    # Populate variables to the object dictionary.    \n",
    "    obj_dict['rctv'] = rctv\n",
    "    obj_dict['path_cctv_view'] = path_cctv_view\n",
    "    obj_dict['pts1'] = pts1\n",
    "    obj_dict['pts2'] = pts2\n",
    "    obj_dict['filename_length'] = filename_length\n",
    "    obj_dict['M'] = M\n",
    "    objs[i] = obj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324-patungkuda utara     \n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "ord_q = ord('q') # For quit button\n",
    "ord_p = ord('p') # For pause button\n",
    "finished = False\n",
    "                \n",
    "# Resize the map image so that it is faster to display\n",
    "RESIZE_CONSTANT = 0.55\n",
    "CCTV_VIEW_RESIZE = 0.25\n",
    "\n",
    "# Other constants\n",
    "TEXT_POSITION    = np.int32(np.array([25, 40]) * RESIZE_CONSTANT)\n",
    "TEXT_SIZE        = 1\n",
    "TEXT_COLOR       = (0, 0, 0)\n",
    "TEXT_BOLDNESS    = round(2 * RESIZE_CONSTANT)\n",
    "POINT_SIZE       = round(10 * RESIZE_CONSTANT)\n",
    "BOX_OUTLINE_SIZE = round(10 * CCTV_VIEW_RESIZE)\n",
    "\n",
    "map_image_resized = cv2.resize(map_image, (0,0), fx=RESIZE_CONSTANT, fy=RESIZE_CONSTANT)\n",
    "force_quit = False\n",
    "\n",
    "\n",
    "# Display the legends\n",
    "LEGEND_CANVAS_SIZE_X = max([len(c) for c in coco_vehicle_labels] + [len('Legends:')]) * 15 + 20\n",
    "LEGEND_CANVAS_SIZE_X += 20 # Add 20 px more for color\n",
    "LEGEND_CANVAS_SIZE_Y = (len(coco_vehicle_labels) + 1) * 35 + 20\n",
    "LEGEND_FONT_SIZE     = 0.8\n",
    "\n",
    "legend_canvas = np.uint8(np.ones((LEGEND_CANVAS_SIZE_Y, LEGEND_CANVAS_SIZE_X, 3)) * 255)\n",
    "cv2.putText(legend_canvas, 'Legends:',\n",
    "            (15, 30), cv2.FONT_HERSHEY_SIMPLEX, LEGEND_FONT_SIZE,\n",
    "            (0, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "for i, label in enumerate(coco_vehicle_labels):\n",
    "    cv2.putText(legend_canvas, label,\n",
    "            (45, 35 * (i+1) + 30), cv2.FONT_HERSHEY_SIMPLEX, LEGEND_FONT_SIZE,\n",
    "            (0, 0, 0), 0, cv2.LINE_AA)\n",
    "    cv2.circle(legend_canvas, (25, 35 * (i+1) + 15 + 5),\n",
    "               10, coco_colors[i].tolist(), -1)\n",
    "    \n",
    "cv2.imshow('Legend', legend_canvas)\n",
    "\n",
    "try:\n",
    "    for i in range(cctv_range['start'], cctv_range['end'] + 1):\n",
    "        \n",
    "        # Copy the image. Later we will draw something.\n",
    "        # We don't want the original to be overwritten.\n",
    "        new_map_image = map_image_resized.copy()\n",
    "        image_cctvs = np.array([[[]]])\n",
    "        \n",
    "        # Give frame number\n",
    "        cv2.putText(new_map_image, 'Frame number: {:}'.format(i),\n",
    "                    tuple(TEXT_POSITION.tolist()),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, TEXT_SIZE * RESIZE_CONSTANT,\n",
    "                    TEXT_COLOR, TEXT_BOLDNESS, cv2.LINE_AA)\n",
    "        \n",
    "        for j in range(len(region_cctv_views)):\n",
    "            obj = objs[j]\n",
    "            \n",
    "            # Print current progress (for debug purposes)\n",
    "            print('\\r' + str(i) + '-' + obj['rctv'] + '   ', end='')\n",
    "            \n",
    "            M = obj['M']\n",
    "            filename_length = obj['filename_length']\n",
    "            path_cctv_view = obj['path_cctv_view']\n",
    "            \n",
    "            csv_file_name = str(i).zfill(filename_length)\n",
    "            csv_path = '{:}/{:}.csv'.format(path_cctv_view, csv_file_name)\n",
    "\n",
    "            # Read CSV\n",
    "            objects = pd.read_csv(csv_path)\n",
    "            \n",
    "            # Eliminate non-vehicles object\n",
    "            n_detection = objects.shape[0]\n",
    "            if (n_detection > 0):\n",
    "                objects = objects[objects.apply(lambda r: eliminate_non_vehicle(r), axis=1)]\n",
    "\n",
    "            # For every bounding box vehicles, find the bounding box center point\n",
    "            n_detection = objects.shape[0]\n",
    "            if (n_detection > 0):\n",
    "                # Get colors\n",
    "                colors = objects['object_probs'].apply(lambda row: get_color_from_class(row)).values.tolist()\n",
    "                centers = objects.apply(lambda r: [\n",
    "                                  (r['left'] + r['right'])/2,\n",
    "                                  (r['top'] + r['bottom'])/2\n",
    "                                  ], axis=1)\n",
    "                \n",
    "                # Transform the points\n",
    "                points_np = np.array([c for c in centers])\n",
    "                points_transform = np.float64(warpPerspectivePoints(points_np, M))\n",
    "                \n",
    "                # Resize the points and the map image so that it is faster to display\n",
    "                points_transform *= RESIZE_CONSTANT\n",
    "                points_transform = np.int32(points_transform)\n",
    "\n",
    "                # Map the points to the image\n",
    "                for k, pts_t in enumerate(points_transform):\n",
    "                    cv2.circle(new_map_image, tuple(pts_t), POINT_SIZE, colors[k].tolist(), -1)\n",
    "            \n",
    "            # Read CCTV image, replacing CSV path with JPG path\n",
    "            cctv_view_image = cv2.imread(csv_path[:-3] + 'jpg')\n",
    "            cctv_view_image = cv2.resize(cctv_view_image, (0,0), fx=CCTV_VIEW_RESIZE, fy=CCTV_VIEW_RESIZE)\n",
    "            \n",
    "            # Draw bounding boxes\n",
    "            if (n_detection > 0):\n",
    "                boxes = objects.apply(lambda r: [\n",
    "                                  [r['left'], r['top']],\n",
    "                                  [r['right'], r['bottom']]\n",
    "                                  ], axis=1)\n",
    "                # Resize the boxes\n",
    "                boxes = np.int32(np.int32([k for k in boxes.values]) * CCTV_VIEW_RESIZE)\n",
    "                for k, box in enumerate(boxes):\n",
    "                    cv2.rectangle(cctv_view_image, tuple(box[0]), tuple(box[1]), tuple(colors[k].tolist()),\n",
    "                                  BOX_OUTLINE_SIZE)\n",
    "            \n",
    "            if (j == 0):\n",
    "                image_cctvs = cctv_view_image\n",
    "            else:\n",
    "                image_cctvs = np.concatenate((image_cctvs, cctv_view_image), axis=0)\n",
    "        \n",
    "        cv2.imshow('Image', new_map_image)\n",
    "        cv2.imshow('Image CCTV', image_cctvs)\n",
    "        if pause_and_is_finished():\n",
    "            force_quit = True\n",
    "            break\n",
    "    \n",
    "    print(\"\\nFinished!\")\n",
    "    if not force_quit:\n",
    "        cv2.putText(new_map_image, 'Frame number: {:} ~FINISHED!'.format('      '),\n",
    "                    tuple(TEXT_POSITION.tolist()),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, TEXT_SIZE * RESIZE_CONSTANT,\n",
    "                    TEXT_COLOR, TEXT_BOLDNESS, cv2.LINE_AA)\n",
    "        cv2.imshow('Image', new_map_image)\n",
    "        \n",
    "        while not pause_and_is_finished():\n",
    "            time.sleep(0.2)\n",
    "finally:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### From this point, the cells below are used for sandbox purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Try for single video frames first\n",
    "try:\n",
    "    rctv = region_cctv_views[2]\n",
    "    path_cctv_view = './frame/cctv_{:}_{:} {:}_x264.mp4/'.format(region_name, rctv, cctv_time)\n",
    "    polygons = get_points(region_coords, rctv)\n",
    "\n",
    "    pts1 = polygons['1']\n",
    "    pts2 = polygons['3']\n",
    "\n",
    "    print(\"VIEW:\", rctv)\n",
    "    print(\"PTS 1:\", str(pts1).replace(\"\\n\", \"\"))\n",
    "    print(\"PTS 2:\", str(pts2).replace(\"\\n\", \"\"))\n",
    "\n",
    "    # Get transformation matrix\n",
    "    M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    pts_transform = np.int32(warpPerspectivePoints(pts1, M))\n",
    "    \n",
    "    # Draw polygon containing the transformed region\n",
    "    overlay_transform = np.uint8(np.ones(map_image.shape)) * 255\n",
    "    cv2.fillPoly(overlay_transform, [np.int32(pts_transform)], (0, 0, 255))\n",
    "    cv2.fillPoly(map_image_filled, [np.int32(pts_transform)], (255, 0, 0))\n",
    "    \n",
    "    print(pts_transform.tolist())\n",
    "\n",
    "    # Get file name length (it is assumed to be same for all the video frames)\n",
    "    file_ext_first_file = os.path.splitext(os.listdir(path_cctv_view)[0])\n",
    "    print(\"FIRST FILE:\", file_ext_first_file)\n",
    "    filename_length = len(file_ext_first_file[0])\n",
    "\n",
    "    coco_vehicle_labels = ['bicycle', 'car', 'motorbike', 'bus', 'truck']\n",
    "\n",
    "    def strip(text):\n",
    "        try:\n",
    "            return text.strip()\n",
    "        except AttributeError:\n",
    "            return text\n",
    "\n",
    "    # Try for single frame video first\n",
    "    # Read CSV detection sequentially\n",
    "    \n",
    "    for i in range(45, cctv_range['end'] + 1):\n",
    "        new_map_image = map_image_filled.copy()\n",
    "        csv_file_name = str(i).zfill(filename_length)\n",
    "        csv_path = '{:}/{:}.csv'.format(path_cctv_view, csv_file_name)\n",
    "\n",
    "        # Read CSV\n",
    "        objects = pd.read_csv(csv_path)\n",
    "        print()\n",
    "        print(\"OBJECTS:\")\n",
    "        print(objects)\n",
    "        print()\n",
    "\n",
    "        # Eliminate non-vehicles object\n",
    "        def eliminate_non_vehicle(series):\n",
    "            detections = series['object_probs'].split(' ')\n",
    "            for dtc in detections:\n",
    "                if dtc in coco_vehicle_labels:\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        objects = objects[objects.apply(lambda r: eliminate_non_vehicle(r), axis=1)]\n",
    "\n",
    "        # Change string columns into numeric\n",
    "        # -- Yeah, a little mistake I did when outputting CSV in darknet :( \n",
    "        #cols = ['left', 'right', 'top', 'bottom']    \n",
    "        #for j in cols:\n",
    "        #    objects[j] = pd.to_numeric(objects[j])\n",
    "\n",
    "        # For every bounding box vehicles, find the bounding box center point    \n",
    "        centers = objects.apply(lambda r: [\n",
    "                          (r['left'] + r['right'])/2,\n",
    "                          (r['top'] + r['bottom'])/2\n",
    "                          ], axis=1)\n",
    "        print(\"CENTERS:\", str(centers).replace(\"\\n\", \"\").replace(\"  \", \" \"))\n",
    "\n",
    "        # Transformation the points\n",
    "        points_np = np.array([i for i in centers])\n",
    "        points_transform = np.int32(warpPerspectivePoints(points_np, M))\n",
    "        print(\"CENTER TRANSFORMED\", str(points_transform).replace(\"\\n\", \"\"))\n",
    "\n",
    "        # Map the points to the image\n",
    "        for i in points_transform:\n",
    "            cv2.circle(new_map_image, tuple(i), 9, (0,255,0), -1)\n",
    "        cv2.imshow('Image2', overlay_transform)\n",
    "\n",
    "        cv2.imshow('Image', new_map_image)\n",
    "        while True:\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "        break\n",
    "finally:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64"
     ]
    }
   ],
   "source": [
    "# Now let's try it for all video frames.\n",
    "try:\n",
    "    rctv = region_cctv_views[1]\n",
    "    path_cctv_view = './frame/cctv_{:}_{:} {:}_x264.mp4/'.format(region_name, rctv, cctv_time)\n",
    "    polygons = get_points(region_coords, rctv)\n",
    "\n",
    "    pts1 = polygons['1']\n",
    "    pts2 = polygons['3']\n",
    "\n",
    "    # Get transformation matrix\n",
    "    M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    pts_transform = np.int32(warpPerspectivePoints(pts1, M))\n",
    "    \n",
    "    # Draw polygon containing the transformed region\n",
    "    overlay_transform = np.uint8(np.ones(map_image.shape)) * 255\n",
    "    map_image_filled = map_image.copy()\n",
    "    cv2.fillPoly(overlay_transform, [np.int32(pts_transform)], (0, 0, 255))\n",
    "\n",
    "    # Get file name length (it is assumed to be same for all the video frames)\n",
    "    file_ext_first_file = os.path.splitext(os.listdir(path_cctv_view)[0])\n",
    "    filename_length = len(file_ext_first_file[0])\n",
    "\n",
    "    coco_vehicle_labels = ['bicycle', 'car', 'motorbike', 'bus', 'truck']\n",
    "\n",
    "    def strip(text):\n",
    "        try:\n",
    "            return text.strip()\n",
    "        except AttributeError:\n",
    "            return text\n",
    "\n",
    "    # Read CSV detection sequentially    \n",
    "    for i in range(cctv_range['start'], cctv_range['end'] + 1):\n",
    "        print('\\r' + str(i), end='')\n",
    "        new_map_image = map_image_filled.copy()\n",
    "        csv_file_name = str(i).zfill(filename_length)\n",
    "        csv_path = '{:}/{:}.csv'.format(path_cctv_view, csv_file_name)\n",
    "        \n",
    "        # Read CSV\n",
    "        objects = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Do not progress if nothing is detected\n",
    "        n_detection = objects.shape[0]\n",
    "        if (n_detection > 0):\n",
    "            \n",
    "            # Eliminate non-vehicles object\n",
    "            def eliminate_non_vehicle(series):\n",
    "                detections = series['object_probs'].split(' ')\n",
    "                for dtc in detections:\n",
    "                    if dtc in coco_vehicle_labels:\n",
    "                        return True\n",
    "                return False\n",
    "\n",
    "            objects = objects[objects.apply(lambda r: eliminate_non_vehicle(r), axis=1)]\n",
    "            \n",
    "        n_detection = objects.shape[0]\n",
    "        if (n_detection > 0):\n",
    "            # For every bounding box vehicles, find the bounding box center point    \n",
    "            centers = objects.apply(lambda r: [\n",
    "                              (r['left'] + r['right'])/2,\n",
    "                              (r['top'] + r['bottom'])/2\n",
    "                              ], axis=1)\n",
    "\n",
    "            # Transformation the points\n",
    "            points_np = np.array([i for i in centers])\n",
    "            points_transform = np.int32(warpPerspectivePoints(points_np, M))\n",
    "            \n",
    "            # Map the points to the image\n",
    "            for i in points_transform:\n",
    "                cv2.circle(new_map_image, tuple(i), 9, (0,255,0), -1)\n",
    "\n",
    "        cv2.imshow('Image', new_map_image)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "finally:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11109: error: (-215) depth == 0 || depth == 2 || depth == 5 in function cv::cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-9b966f5b8307>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrgbimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_HSV2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11109: error: (-215) depth == 0 || depth == 2 || depth == 5 in function cv::cvtColor\n"
     ]
    }
   ],
   "source": [
    "rgbimg = cv2.cvtColor(np.float64([0, 0, 100]), cv2.COLOR_HSV2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255]],\n",
       "\n",
       "       [[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255]],\n",
       "\n",
       "       [[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255]],\n",
       "\n",
       "       [[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255]],\n",
       "\n",
       "       [[  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        ...,\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255],\n",
       "        [  0,   0, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.cvtColor(new_map_image, cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56 [255 238   0]           "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-bfcf899e20a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m360\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_HSV2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'           '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(0, 360):\n",
    "    print('\\r', i, np.uint8(cv2.cvtColor(np.float32([[[i, 1, 1]]]), cv2.COLOR_HSV2RGB)[0, 0] * 255), end='           ')\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.uint8([[new_map_image[0,0]]]).tolist()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[104, 255,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.uint8([[[360,255,0 ]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
