{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detector Dashboard\n",
    "\n",
    "This Notebook is useful to display pre-rendered YOLOv3 detections.\n",
    "The detection information is stored inside CSV files along with\n",
    "frames of the original video. If you have those two files, you\n",
    "should be able to run this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can freely change this depending on the condition of your database.\n",
    "region_name = \"SIMPANG 4 PATUNG KUDA\"\n",
    "cctv_range = {'start':0, 'end': 3300}\n",
    "cctv_time = '1200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cctv_folder_parent</th>\n",
       "      <th>map_image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SIMPANG 3 DPR</td>\n",
       "      <td>SIMPANG 3 DPR.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SIMPANG 4 CUNGKING</td>\n",
       "      <td>SIMPANG 4 CUNGKING.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SIMPANG 4 PATUNG KUDA</td>\n",
       "      <td>SIMPANG 4 PATUNG KUDA.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SIMPANG 5 PUSAT KOTA</td>\n",
       "      <td>SIMPANG 5 BANYUWANGI.jpeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cctv_folder_parent              map_image_name\n",
       "0          SIMPANG 3 DPR          SIMPANG 3 DPR.jpeg\n",
       "1     SIMPANG 4 CUNGKING     SIMPANG 4 CUNGKING.jpeg\n",
       "2  SIMPANG 4 PATUNG KUDA  SIMPANG 4 PATUNG KUDA.jpeg\n",
       "3   SIMPANG 5 PUSAT KOTA   SIMPANG 5 BANYUWANGI.jpeg"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "region_data = pd.read_csv('regions.csv')\n",
    "region_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_name</th>\n",
       "      <th>cctv_view_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SIMPANG 3 DPR</td>\n",
       "      <td>dpr selatan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SIMPANG 3 DPR</td>\n",
       "      <td>dpr timur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SIMPANG 3 DPR</td>\n",
       "      <td>dpr utara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SIMPANG 4 PATUNG KUDA</td>\n",
       "      <td>patungkuda barat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SIMPANG 4 PATUNG KUDA</td>\n",
       "      <td>patungkuda selatan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SIMPANG 4 PATUNG KUDA</td>\n",
       "      <td>patungkuda utara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SIMPANG 4 CUNGKING</td>\n",
       "      <td>cungking selatan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SIMPANG 4 CUNGKING</td>\n",
       "      <td>cungking timur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SIMPANG 4 CUNGKING</td>\n",
       "      <td>cungking utara</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             region_name      cctv_view_name\n",
       "0          SIMPANG 3 DPR         dpr selatan\n",
       "1          SIMPANG 3 DPR           dpr timur\n",
       "2          SIMPANG 3 DPR           dpr utara\n",
       "3  SIMPANG 4 PATUNG KUDA    patungkuda barat\n",
       "4  SIMPANG 4 PATUNG KUDA  patungkuda selatan\n",
       "5  SIMPANG 4 PATUNG KUDA    patungkuda utara\n",
       "6     SIMPANG 4 CUNGKING    cungking selatan\n",
       "7     SIMPANG 4 CUNGKING      cungking timur\n",
       "8     SIMPANG 4 CUNGKING      cungking utara"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cctv_data = pd.read_csv('cctv_views.csv')\n",
    "cctv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCTV VIEWS : ['patungkuda barat', 'patungkuda selatan', 'patungkuda utara']\n",
      "MAP PATH   : map/SIMPANG 4 PATUNG KUDA.jpeg\n",
      "REGION COORDINATES:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>view</th>\n",
       "      <th>pt1a</th>\n",
       "      <th>pt1b</th>\n",
       "      <th>pt1c</th>\n",
       "      <th>pt1d</th>\n",
       "      <th>pt2a</th>\n",
       "      <th>pt2b</th>\n",
       "      <th>pt2c</th>\n",
       "      <th>pt2d</th>\n",
       "      <th>pt3a</th>\n",
       "      <th>pt3b</th>\n",
       "      <th>pt3c</th>\n",
       "      <th>pt3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patungkuda selatan</td>\n",
       "      <td>97 273</td>\n",
       "      <td>363 236</td>\n",
       "      <td>1074 476</td>\n",
       "      <td>187 770</td>\n",
       "      <td>0 0</td>\n",
       "      <td>1080 0</td>\n",
       "      <td>1080 720</td>\n",
       "      <td>0 720</td>\n",
       "      <td>400 717</td>\n",
       "      <td>295 644</td>\n",
       "      <td>392 513</td>\n",
       "      <td>492 587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patungkuda barat</td>\n",
       "      <td>132 283</td>\n",
       "      <td>396 262</td>\n",
       "      <td>1080 505</td>\n",
       "      <td>211 720</td>\n",
       "      <td>0 0</td>\n",
       "      <td>1080 0</td>\n",
       "      <td>1080 720</td>\n",
       "      <td>0 720</td>\n",
       "      <td>364 296</td>\n",
       "      <td>475 236</td>\n",
       "      <td>578 379</td>\n",
       "      <td>458 450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patungkuda utara</td>\n",
       "      <td>510 170</td>\n",
       "      <td>668 168</td>\n",
       "      <td>664 437</td>\n",
       "      <td>0 390</td>\n",
       "      <td>0 0</td>\n",
       "      <td>1080 0</td>\n",
       "      <td>1080 720</td>\n",
       "      <td>0 720</td>\n",
       "      <td>648 167</td>\n",
       "      <td>748 239</td>\n",
       "      <td>598 437</td>\n",
       "      <td>497 362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 view     pt1a      pt1b       pt1c      pt1d pt2a     pt2b  \\\n",
       "0  patungkuda selatan   97 273   363 236   1074 476   187 770  0 0   1080 0   \n",
       "1    patungkuda barat  132 283   396 262   1080 505   211 720  0 0   1080 0   \n",
       "2    patungkuda utara  510 170   668 168    664 437     0 390  0 0   1080 0   \n",
       "\n",
       "       pt2c   pt2d      pt3a      pt3b      pt3c      pt3d  \n",
       "0  1080 720  0 720   400 717   295 644   392 513   492 587  \n",
       "1  1080 720  0 720   364 296   475 236   578 379   458 450  \n",
       "2  1080 720  0 720   648 167   748 239   598 437   497 362  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a CCTV path of image whose region has been detected\n",
    "# Define the map path as well.\n",
    "\n",
    "region_cctv_views = cctv_data[cctv_data['region_name'] == region_name]['cctv_view_name'].values.tolist()\n",
    "\n",
    "region_map_path = region_data[region_data['cctv_folder_parent'] == region_name]\n",
    "region_map_path = 'map/' + region_map_path['map_image_name'].values.tolist()[0]\n",
    "\n",
    "region_coords = pd.read_csv('coords/cctv/{:}.csv'.format(region_name))\n",
    "\n",
    "print(\"CCTV VIEWS :\", region_cctv_views)\n",
    "print(\"MAP PATH   :\", region_map_path)\n",
    "print(\"REGION COORDINATES:\")\n",
    "region_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_image = cv2.imread(region_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points(pandas_frame, view_name):\n",
    "    polygons = {}\n",
    "    row = pandas_frame[pandas_frame['view'] == view_name]\n",
    "    point_id = ['a', 'b', 'c', 'd']\n",
    "    polygon_id = ['1', '2', '3']\n",
    "    for i in polygon_id:\n",
    "        polygon = []\n",
    "        for j in point_id:\n",
    "            point_name = 'pt'+ i + j\n",
    "            point_array = [int(p) for p in row[point_name].values.tolist()[0].split()]\n",
    "            polygon.append(point_array)\n",
    "        polygons[i] = np.float32(polygon)\n",
    "    return polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warpPerspectivePoints(pts, M):\n",
    "    n = pts.shape[0]\n",
    "    trans = np.hstack((pts, np.ones((n,1)))) # Add ones at the bottom of matrix\n",
    "    trans = np.matmul(M, np.transpose(trans))\n",
    "    return np.transpose(trans[0:2,:] / trans[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pseudocode:\n",
    "\n",
    "For every CCTV views:\n",
    "\n",
    "1. Eliminate non-vehicles point (can be obtained from the \"object\" header)\n",
    "   For example, vehicles: truck, car, motorbike\n",
    "1. For every bounding box vehicles:\n",
    "   1. Find the bounding box center point\n",
    "   1. Map the point according to transformation matrix M\n",
    "1. Now, for displaying purposes:\n",
    "   1. Draw the map and all the transformed points\n",
    "   1. In new window, draw the CCTV image with boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_vehicle_labels = ['bicycle', 'car', 'motorbike', 'bus', 'truck']\n",
    "\n",
    "def eliminate_non_vehicle(series):\n",
    "    detections = series['object_probs'].split(' ')\n",
    "    if detections[0] in coco_vehicle_labels:\n",
    "        return detections[0]\n",
    "    return None\n",
    "\n",
    "ord_q = ord('q') # For quit button\n",
    "ord_p = ord('p') # For pause button\n",
    "\n",
    "def pause_and_is_finished():\n",
    "    # Pauses and quit button purposes\n",
    "    k = cv2.waitKey(25) & 0xFF\n",
    "    finished = k == ord_q\n",
    "    if k == ord_p:\n",
    "        while True:\n",
    "            k = cv2.waitKey(25) & 0xFF\n",
    "            finished = k == ord_q\n",
    "            if k == ord_p or k == ord_q:\n",
    "                break\n",
    "    return finished\n",
    "\n",
    "def generate_equal_rgb_color_distance(n):\n",
    "    colors = []\n",
    "    for i in range(n):\n",
    "        color = np.uint8(cv2.cvtColor(np.float32([[[i*360/n, 0.8, 0.9]]]), cv2.COLOR_HSV2RGB)[0, 0] * 255)\n",
    "        colors.append(color)\n",
    "    return colors\n",
    "\n",
    "coco_colors = generate_equal_rgb_color_distance(len(coco_vehicle_labels))\n",
    "coco_colors\n",
    "\n",
    "def get_color_from_class(row):\n",
    "    class_name = row.split()[0]\n",
    "    class_index = coco_vehicle_labels.index(class_name)\n",
    "    return coco_colors[class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a dictionary to store variables.\n",
    "# These variables include precomputed value as well, such as\n",
    "# the transformation matrix.\n",
    "\n",
    "objs = {}\n",
    "for i in range(len(region_cctv_views)):\n",
    "    obj_dict = {}\n",
    "    \n",
    "    rctv = region_cctv_views[i]\n",
    "    path_cctv_view = './frame/cctv_{:}_{:} {:}_x264.mp4/'.format(region_name, rctv, cctv_time)\n",
    "    \n",
    "    polygons = get_points(region_coords, rctv)\n",
    "\n",
    "    pts1 = polygons['1']\n",
    "    pts2 = polygons['3']\n",
    "\n",
    "    # Get transformation matrix\n",
    "    M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    pts_transform = np.int32(warpPerspectivePoints(pts1, M))    \n",
    "\n",
    "    # Get detections CSV file name length\n",
    "    # It is assumed that all files has the same name length.\n",
    "    file_ext_first_file = os.path.splitext(os.listdir(path_cctv_view)[0])\n",
    "    filename_length = len(file_ext_first_file[0])\n",
    "    \n",
    "    # Populate variables to the object dictionary.    \n",
    "    obj_dict['rctv'] = rctv\n",
    "    obj_dict['path_cctv_view'] = path_cctv_view\n",
    "    obj_dict['pts1'] = pts1\n",
    "    obj_dict['pts2'] = pts2\n",
    "    obj_dict['filename_length'] = filename_length\n",
    "    obj_dict['M'] = M\n",
    "    obj_dict['previous_objects'] = pd.DataFrame(columns=['object_probs', 'left', 'top', 'right' , 'bottom'])\n",
    "    objs[i] = obj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the map image so that it is faster to display\n",
    "RESIZE_CONSTANT = 0.55\n",
    "CCTV_VIEW_RESIZE = 0.25\n",
    "\n",
    "# Constants for CCTV text, map points, and box display\n",
    "TEXT_POSITION    = np.int32(np.array([25, 40]) * RESIZE_CONSTANT)\n",
    "TEXT_SIZE        = 1\n",
    "TEXT_COLOR       = (0, 0, 0)\n",
    "TEXT_BOLDNESS    = round(2 * RESIZE_CONSTANT)\n",
    "POINT_SIZE       = round(10 * RESIZE_CONSTANT)\n",
    "BOX_OUTLINE_SIZE = round(10 * CCTV_VIEW_RESIZE)\n",
    "    \n",
    "# Constants for legends\n",
    "MAX_CHARACTER_LENGTH   = max([len(c) for c in coco_vehicle_labels] + [len('Legends:')]) + 3\n",
    "CHARACTER_WIDTH        = 15\n",
    "CHARACTER_HEIGHT       = 35\n",
    "LEGEND_CANVAS_SIZE_X   = MAX_CHARACTER_LENGTH * CHARACTER_WIDTH + 40 # Add 40 px more for color label\n",
    "LEGEND_CANVAS_SIZE_Y   = len(coco_vehicle_labels) + 2 # Add 2 more rows for \"Legends\" label and \"Total:\" label\n",
    "LEGEND_CANVAS_SIZE_Y   = LEGEND_CANVAS_SIZE_Y * CHARACTER_HEIGHT + 20\n",
    "CIRCLE_SIZE            = 10\n",
    "LEGEND_FONT_SIZE       = 0.8\n",
    "LEGEND_LABEL_FONT_SIZE = 0.6\n",
    "LEGEND_FONT_COLOR      = (0,0,0)\n",
    "LEGEND_LABEL_OUTLINE   = 0\n",
    "LEGEND_TITLE_POS       = (15, 30)\n",
    "LEGEND_TITLE_OUTLINE   = 2\n",
    "LEGEND_TOTAL_TEXT_POS  = (15, (len(coco_vehicle_labels) + 1) * CHARACTER_HEIGHT + 30)\n",
    "\n",
    "def display_legends(vehicle_count):\n",
    "    total_vehicle = np.sum(vehicle_count)\n",
    "    legend_canvas = np.uint8(np.ones((LEGEND_CANVAS_SIZE_Y, LEGEND_CANVAS_SIZE_X, 3)) * 255)\n",
    "    cv2.putText(legend_canvas, 'LEGENDS:', LEGEND_TITLE_POS, cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                LEGEND_FONT_SIZE, LEGEND_FONT_COLOR, LEGEND_TITLE_OUTLINE, cv2.LINE_AA)\n",
    "\n",
    "    for i, label in enumerate(coco_vehicle_labels):\n",
    "        LABEL_CIRCLE_POS = (25, 35 * (i+1) + 25)\n",
    "        LABEL_TEXT_POS   = (45, 35 * (i+1) + 30)\n",
    "        LABEL_TEXT       = '{:} ({:})'.format(label, vehicle_count[i])\n",
    "        \n",
    "        cv2.putText(legend_canvas, LABEL_TEXT, LABEL_TEXT_POS,\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, LEGEND_LABEL_FONT_SIZE,\n",
    "                    LEGEND_FONT_COLOR, LEGEND_LABEL_OUTLINE, cv2.LINE_AA)\n",
    "        cv2.circle(legend_canvas, LABEL_CIRCLE_POS, CIRCLE_SIZE, coco_colors[i].tolist(), -1)\n",
    "    cv2.putText(legend_canvas, 'Total: {:}'.format(total_vehicle), LEGEND_TOTAL_TEXT_POS,\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, LEGEND_FONT_SIZE, LEGEND_FONT_COLOR,\n",
    "                LEGEND_LABEL_OUTLINE, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('Legend', legend_canvas)\n",
    "    \n",
    "def display_vehicle_total_count(vehicle_total_count):\n",
    "    fig = Figure()\n",
    "    canvas = FigureCanvas(fig)\n",
    "    ax = fig.gca()\n",
    "    ax.plot(vehicle_total_count)\n",
    "    ax.set_title('Vehicle count')\n",
    "\n",
    "    canvas.draw()\n",
    "    total_vehicle_image = np.fromstring(canvas.tostring_rgb(), dtype='uint8')\n",
    "    width, height = np.int32(fig.get_size_inches() * fig.get_dpi())\n",
    "    total_vehicle_image = np.reshape(total_vehicle_image, (height, width, 3))\n",
    "    total_vehicle_image = cv2.cvtColor(total_vehicle_image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    cv2.imshow('Vehicle count', total_vehicle_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:58: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    }
   ],
   "source": [
    "map_image_resized = cv2.resize(map_image, (0,0), fx=RESIZE_CONSTANT, fy=RESIZE_CONSTANT)\n",
    "force_quit = False\n",
    "total_vehicle_over_time = np.int32([])\n",
    "\n",
    "try:\n",
    "    for i in range(cctv_range['start'], cctv_range['end'] + 1):\n",
    "        \n",
    "        # Copy the image. Later we will draw something.\n",
    "        # We don't want the original to be overwritten.\n",
    "        new_map_image = map_image_resized.copy()\n",
    "        \n",
    "        # This is canvas for displaying all of the CCTV views\n",
    "        image_cctvs = np.array([[[]]])\n",
    "        \n",
    "        # Give frame number\n",
    "        cv2.putText(new_map_image, 'Frame number: {:}'.format(i),\n",
    "                    tuple(TEXT_POSITION.tolist()),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, TEXT_SIZE * RESIZE_CONSTANT,\n",
    "                    TEXT_COLOR, TEXT_BOLDNESS, cv2.LINE_AA)\n",
    "        \n",
    "        # Initiate vehicle counter\n",
    "        vehicle_count = np.int32(np.zeros(len(coco_vehicle_labels)))\n",
    "        for j in range(len(region_cctv_views)):\n",
    "            obj = objs[j]\n",
    "            \n",
    "            M = obj['M']\n",
    "            filename_length = obj['filename_length']\n",
    "            path_cctv_view = obj['path_cctv_view']\n",
    "            \n",
    "            csv_file_name = str(i).zfill(filename_length)\n",
    "            csv_path = '{:}/{:}.csv'.format(path_cctv_view, csv_file_name)\n",
    "            \n",
    "            # Read CSV\n",
    "            if os.path.exists(csv_path):\n",
    "                objects = pd.read_csv(csv_path)\n",
    "                obj['previous_objects'] = objects\n",
    "            else:\n",
    "                # If there's no CSV files found, use previous detection\n",
    "                # even though the result might jitter.\n",
    "                objects = obj['previous_objects']\n",
    "\n",
    "            n_detection = objects.shape[0]\n",
    "            if (n_detection > 0):\n",
    "                # Eliminate non-vehicles object\n",
    "                vehicle_labels = objects.apply(lambda r: eliminate_non_vehicle(r), axis=1)\n",
    "                objects = objects[~vehicle_labels.isna()]\n",
    "                vehicle_labels = vehicle_labels[~vehicle_labels.isna()]\n",
    "\n",
    "                # Count the vehicles\n",
    "                vehicle_count += [(vehicle_labels == l).sum() for l in coco_vehicle_labels]\n",
    "\n",
    "            n_detection = objects.shape[0]\n",
    "            if (n_detection > 0):\n",
    "                # For every bounding box vehicles, find the bounding box center of mass\n",
    "                centers = objects.apply(lambda r: [\n",
    "                                  (r['left'] + r['right'])/2,\n",
    "                                  (r['top'] + r['bottom'])/2\n",
    "                                  ], axis=1)\n",
    "\n",
    "                # Transform the points\n",
    "                points_np = np.array([c for c in centers])\n",
    "                points_transform = np.float64(warpPerspectivePoints(points_np, M))\n",
    "\n",
    "                # Resize the points and the map image so that it is faster to display\n",
    "                points_transform = np.int32(points_transform * RESIZE_CONSTANT)\n",
    "\n",
    "                # Get colors\n",
    "                colors = objects['object_probs'].apply(lambda row: get_color_from_class(row)).values.tolist()\n",
    "\n",
    "                # Map the points to the image\n",
    "                for k, pts_t in enumerate(points_transform):\n",
    "                    cv2.circle(new_map_image, tuple(pts_t), POINT_SIZE, colors[k].tolist(), -1)\n",
    "            \n",
    "            # Read CCTV image, replacing CSV path with JPG path\n",
    "            cctv_view_image = cv2.imread(csv_path[:-3] + 'jpg')\n",
    "            cctv_view_image = cv2.resize(cctv_view_image, (0,0), fx=CCTV_VIEW_RESIZE, fy=CCTV_VIEW_RESIZE)\n",
    "            \n",
    "            if (n_detection > 0):\n",
    "                boxes = objects.apply(lambda r: [\n",
    "                                  [r['left'], r['top']],\n",
    "                                  [r['right'], r['bottom']]\n",
    "                                  ], axis=1)\n",
    "                # Resize and draw the bounding boxes\n",
    "                boxes = np.int32(np.int32([k for k in boxes.values]) * CCTV_VIEW_RESIZE)\n",
    "                for k, box in enumerate(boxes):\n",
    "                    cv2.rectangle(cctv_view_image, tuple(box[0]), tuple(box[1]), tuple(colors[k].tolist()),\n",
    "                                  BOX_OUTLINE_SIZE)\n",
    "            \n",
    "            if (j == 0):\n",
    "                image_cctvs = cctv_view_image\n",
    "            else:\n",
    "                image_cctvs = np.concatenate((image_cctvs, cctv_view_image), axis=0)\n",
    "        \n",
    "        total_vehicle_over_time = np.append(total_vehicle_over_time, [np.sum(vehicle_count)])\n",
    "        \n",
    "        cv2.imshow('Image', new_map_image)\n",
    "        cv2.imshow('Image CCTV', image_cctvs)\n",
    "        display_legends(vehicle_count)\n",
    "        display_vehicle_total_count(total_vehicle_over_time)\n",
    "        \n",
    "        if pause_and_is_finished():\n",
    "            force_quit = True\n",
    "            break\n",
    "    \n",
    "    if not force_quit:\n",
    "        cv2.putText(new_map_image, 'Frame number: {:} ~FINISHED!'.format('      '),\n",
    "                    tuple(TEXT_POSITION.tolist()),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, TEXT_SIZE * RESIZE_CONSTANT,\n",
    "                    TEXT_COLOR, TEXT_BOLDNESS, cv2.LINE_AA)\n",
    "        cv2.imshow('Image', new_map_image)\n",
    "        \n",
    "        while not pause_and_is_finished():\n",
    "            pass\n",
    "finally:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### From this point, the cells below are used for sandbox purposes only."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Try for single video frames first\n",
    "try:\n",
    "    rctv = region_cctv_views[2]\n",
    "    path_cctv_view = './frame/cctv_{:}_{:} {:}_x264.mp4/'.format(region_name, rctv, cctv_time)\n",
    "    polygons = get_points(region_coords, rctv)\n",
    "\n",
    "    pts1 = polygons['1']\n",
    "    pts2 = polygons['3']\n",
    "\n",
    "    print(\"VIEW:\", rctv)\n",
    "    print(\"PTS 1:\", str(pts1).replace(\"\\n\", \"\"))\n",
    "    print(\"PTS 2:\", str(pts2).replace(\"\\n\", \"\"))\n",
    "\n",
    "    # Get transformation matrix\n",
    "    M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    pts_transform = np.int32(warpPerspectivePoints(pts1, M))\n",
    "    \n",
    "    # Draw polygon containing the transformed region\n",
    "    overlay_transform = np.uint8(np.ones(map_image.shape)) * 255\n",
    "    cv2.fillPoly(overlay_transform, [np.int32(pts_transform)], (0, 0, 255))\n",
    "    cv2.fillPoly(map_image_filled, [np.int32(pts_transform)], (255, 0, 0))\n",
    "    \n",
    "    print(pts_transform.tolist())\n",
    "\n",
    "    # Get file name length (it is assumed to be same for all the video frames)\n",
    "    file_ext_first_file = os.path.splitext(os.listdir(path_cctv_view)[0])\n",
    "    print(\"FIRST FILE:\", file_ext_first_file)\n",
    "    filename_length = len(file_ext_first_file[0])\n",
    "\n",
    "    coco_vehicle_labels = ['bicycle', 'car', 'motorbike', 'bus', 'truck']\n",
    "\n",
    "    def strip(text):\n",
    "        try:\n",
    "            return text.strip()\n",
    "        except AttributeError:\n",
    "            return text\n",
    "\n",
    "    # Try for single frame video first\n",
    "    # Read CSV detection sequentially\n",
    "    \n",
    "    for i in range(45, cctv_range['end'] + 1):\n",
    "        new_map_image = map_image_filled.copy()\n",
    "        csv_file_name = str(i).zfill(filename_length)\n",
    "        csv_path = '{:}/{:}.csv'.format(path_cctv_view, csv_file_name)\n",
    "\n",
    "        # Read CSV\n",
    "        objects = pd.read_csv(csv_path)\n",
    "        print()\n",
    "        print(\"OBJECTS:\")\n",
    "        print(objects)\n",
    "        print()\n",
    "\n",
    "        # Eliminate non-vehicles object\n",
    "        def eliminate_non_vehicle(series):\n",
    "            detections = series['object_probs'].split(' ')\n",
    "            for dtc in detections:\n",
    "                if dtc in coco_vehicle_labels:\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        objects = objects[objects.apply(lambda r: eliminate_non_vehicle(r), axis=1)]\n",
    "\n",
    "        # Change string columns into numeric\n",
    "        # -- Yeah, a little mistake I did when outputting CSV in darknet :( \n",
    "        #cols = ['left', 'right', 'top', 'bottom']    \n",
    "        #for j in cols:\n",
    "        #    objects[j] = pd.to_numeric(objects[j])\n",
    "\n",
    "        # For every bounding box vehicles, find the bounding box center point    \n",
    "        centers = objects.apply(lambda r: [\n",
    "                          (r['left'] + r['right'])/2,\n",
    "                          (r['top'] + r['bottom'])/2\n",
    "                          ], axis=1)\n",
    "        print(\"CENTERS:\", str(centers).replace(\"\\n\", \"\").replace(\"  \", \" \"))\n",
    "\n",
    "        # Transformation the points\n",
    "        points_np = np.array([i for i in centers])\n",
    "        points_transform = np.int32(warpPerspectivePoints(points_np, M))\n",
    "        print(\"CENTER TRANSFORMED\", str(points_transform).replace(\"\\n\", \"\"))\n",
    "\n",
    "        # Map the points to the image\n",
    "        for i in points_transform:\n",
    "            cv2.circle(new_map_image, tuple(i), 9, (0,255,0), -1)\n",
    "        cv2.imshow('Image2', overlay_transform)\n",
    "\n",
    "        cv2.imshow('Image', new_map_image)\n",
    "        while True:\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "        break\n",
    "finally:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Now let's try it for all video frames.\n",
    "try:\n",
    "    rctv = region_cctv_views[1]\n",
    "    path_cctv_view = './frame/cctv_{:}_{:} {:}_x264.mp4/'.format(region_name, rctv, cctv_time)\n",
    "    polygons = get_points(region_coords, rctv)\n",
    "\n",
    "    pts1 = polygons['1']\n",
    "    pts2 = polygons['3']\n",
    "\n",
    "    # Get transformation matrix\n",
    "    M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    pts_transform = np.int32(warpPerspectivePoints(pts1, M))\n",
    "    \n",
    "    # Draw polygon containing the transformed region\n",
    "    overlay_transform = np.uint8(np.ones(map_image.shape)) * 255\n",
    "    map_image_filled = map_image.copy()\n",
    "    cv2.fillPoly(overlay_transform, [np.int32(pts_transform)], (0, 0, 255))\n",
    "\n",
    "    # Get file name length (it is assumed to be same for all the video frames)\n",
    "    file_ext_first_file = os.path.splitext(os.listdir(path_cctv_view)[0])\n",
    "    filename_length = len(file_ext_first_file[0])\n",
    "\n",
    "    coco_vehicle_labels = ['bicycle', 'car', 'motorbike', 'bus', 'truck']\n",
    "\n",
    "    def strip(text):\n",
    "        try:\n",
    "            return text.strip()\n",
    "        except AttributeError:\n",
    "            return text\n",
    "\n",
    "    # Read CSV detection sequentially    \n",
    "    for i in range(cctv_range['start'], cctv_range['end'] + 1):\n",
    "        print('\\r' + str(i), end='')\n",
    "        new_map_image = map_image_filled.copy()\n",
    "        csv_file_name = str(i).zfill(filename_length)\n",
    "        csv_path = '{:}/{:}.csv'.format(path_cctv_view, csv_file_name)\n",
    "        \n",
    "        # Read CSV\n",
    "        objects = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Do not progress if nothing is detected\n",
    "        n_detection = objects.shape[0]\n",
    "        if (n_detection > 0):\n",
    "            \n",
    "            # Eliminate non-vehicles object\n",
    "            def eliminate_non_vehicle(series):\n",
    "                detections = series['object_probs'].split(' ')\n",
    "                for dtc in detections:\n",
    "                    if dtc in coco_vehicle_labels:\n",
    "                        return True\n",
    "                return False\n",
    "\n",
    "            objects = objects[objects.apply(lambda r: eliminate_non_vehicle(r), axis=1)]\n",
    "            \n",
    "        n_detection = objects.shape[0]\n",
    "        if (n_detection > 0):\n",
    "            # For every bounding box vehicles, find the bounding box center point    \n",
    "            centers = objects.apply(lambda r: [\n",
    "                              (r['left'] + r['right'])/2,\n",
    "                              (r['top'] + r['bottom'])/2\n",
    "                              ], axis=1)\n",
    "\n",
    "            # Transformation the points\n",
    "            points_np = np.array([i for i in centers])\n",
    "            points_transform = np.int32(warpPerspectivePoints(points_np, M))\n",
    "            \n",
    "            # Map the points to the image\n",
    "            for i in points_transform:\n",
    "                cv2.circle(new_map_image, tuple(i), 9, (0,255,0), -1)\n",
    "\n",
    "        cv2.imshow('Image', new_map_image)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "finally:\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
